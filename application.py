import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
import matplotlib.pyplot as plt
import seaborn as sns
import tempfile
import os
import io
import traceback

# Importer les biblioth√®ques fairlearn si elles sont disponibles
try:
    from fairlearn.metrics import demographic_parity_difference, equalized_odds_difference
    from fairlearn.metrics import MetricFrame, selection_rate
    from fairlearn.reductions import ExponentiatedGradient, DemographicParity, EqualizedOdds
    FAIRLEARN_AVAILABLE = True
except ImportError:
    FAIRLEARN_AVAILABLE = False
    st.warning("La biblioth√®que fairlearn n'est pas install√©e. Certaines fonctionnalit√©s d'√©quit√© avanc√©es ne seront pas disponibles.")

# Configuration de la page
st.set_page_config(
    page_title="Analyse d'√âquit√© Algorithmique",
    page_icon="‚öñÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Style CSS personnalis√©
st.markdown("""
    <style>
    .main {
        padding: 0rem 1rem;
    }
    .stTitle {
        color: white;
        background-color: #4C4CFF;
        padding: 1rem;
        border-radius: 5px;
    }
    .stSubheader {
        color: #4C4CFF;
    }
    </style>
    """, unsafe_allow_html=True)

# Fonctions d'√©quit√©
def demographic_parity(y_pred, sensitive_attr, sensitive_encoder=None):
    """
    Calcule la parit√© d√©mographique entre les groupes.
    Formule: P(≈∂=1|A=a) = P(≈∂=1|A=b)
    """
    groups = np.unique(sensitive_attr)
    results = {}
    
    for group in groups:
        group_mask = (sensitive_attr == group)
        positive_rate = np.mean(y_pred[group_mask])
        if sensitive_encoder is not None:
            group_name = sensitive_encoder.inverse_transform([group])[0]
        else:
            group_name = f"Groupe {group}"
        results[group_name] = positive_rate
    
    disparity = max(results.values()) - min(results.values())
    return results, disparity

def equalized_odds(y_true, y_pred, sensitive_attr, sensitive_encoder=None):
    """
    Calcule l'√©galit√© des taux d'erreurs entre les groupes.
    Formule: P(≈∂=1|A=a,Y=y) = P(≈∂=1|A=b,Y=y) pour y ‚àà {0,1}
    """
    groups = np.unique(sensitive_attr)
    results = {}
    
    for group in groups:
        group_mask = (sensitive_attr == group)
        
        # Taux de vrais positifs (TPR)
        tp_mask = (y_true == 1) & group_mask
        if np.sum(y_true[group_mask] == 1) > 0:
            tpr = np.sum(y_pred[tp_mask]) / np.sum(y_true[group_mask] == 1)
        else:
            tpr = np.nan
            
        # Taux de faux positifs (FPR)
        fp_mask = (y_true == 0) & group_mask
        if np.sum(y_true[group_mask] == 0) > 0:
            fpr = np.sum(y_pred[fp_mask]) / np.sum(y_true[group_mask] == 0)
        else:
            fpr = np.nan
            
        if sensitive_encoder is not None:
            group_name = sensitive_encoder.inverse_transform([group])[0]
        else:
            group_name = f"Groupe {group}"
        results[group_name] = {"TPR": tpr, "FPR": fpr}
    
    tpr_disparity = max([r["TPR"] for r in results.values()]) - min([r["TPR"] for r in results.values()]) if not np.isnan([r["TPR"] for r in results.values()]).any() else np.nan
    fpr_disparity = max([r["FPR"] for r in results.values()]) - min([r["FPR"] for r in results.values()]) if not np.isnan([r["FPR"] for r in results.values()]).any() else np.nan
    
    return results, tpr_disparity, fpr_disparity

def equal_opportunity(y_true, y_pred, sensitive_attr, sensitive_encoder=None):
    """
    Calcule l'√©galit√© des chances entre les groupes.
    Formule: P(≈∂=1|A=a,Y=1) = P(≈∂=1|A=b,Y=1)
    """
    groups = np.unique(sensitive_attr)
    results = {}
    
    for group in groups:
        group_mask = (sensitive_attr == group)
        positive_mask = (y_true == 1) & group_mask
        
        if np.sum(y_true[group_mask] == 1) > 0:
            tpr = np.sum(y_pred[positive_mask]) / np.sum(y_true[group_mask] == 1)
        else:
            tpr = np.nan
            
        if sensitive_encoder is not None:
            group_name = sensitive_encoder.inverse_transform([group])[0]
        else:
            group_name = f"Groupe {group}"
        results[group_name] = tpr
    
    disparity = max(results.values()) - min(results.values()) if not np.isnan(list(results.values())).any() else np.nan
    return results, disparity

def predictive_parity(y_true, y_pred, sensitive_attr, sensitive_encoder=None):
    """
    Calcule l'√©quilibre des taux de pr√©cision entre les groupes.
    Formule: P(Y=1|A=a,≈∂=1) = P(Y=1|A=b,≈∂=1)
    """
    groups = np.unique(sensitive_attr)
    results = {}
    
    for group in groups:
        group_mask = (sensitive_attr == group)
        predicted_positive_mask = (y_pred == 1) & group_mask
        
        if np.sum(predicted_positive_mask) > 0:
            precision = np.sum((y_true == 1) & predicted_positive_mask) / np.sum(predicted_positive_mask)
        else:
            precision = np.nan
            
        if sensitive_encoder is not None:
            group_name = sensitive_encoder.inverse_transform([group])[0]
        else:
            group_name = f"Groupe {group}"
        results[group_name] = precision
    
    disparity = max(results.values()) - min(results.values()) if not np.isnan(list(results.values())).any() else np.nan
    return results, disparity

# Techniques de mitigation des biais
def reweighing(X, y, sensitive_attr):
    """
    Applique la technique de repond√©ration pour att√©nuer les biais.
    """
    n_samples = len(y)
    unique_groups = np.unique(sensitive_attr)
    unique_labels = np.unique(y)
    
    # Calculer les fr√©quences
    weights = np.ones(n_samples)
    for group in unique_groups:
        for label in unique_labels:
            idx = (sensitive_attr == group) & (y == label)
            count = np.sum(idx)
            if count == 0:
                continue
                
            # P(A=a, Y=y)
            p_ay = count / n_samples
            
            # P(A=a) x P(Y=y)
            p_a = np.sum(sensitive_attr == group) / n_samples
            p_y = np.sum(y == label) / n_samples
            expected_p_ay = p_a * p_y
            
            # Poids: P(A=a) x P(Y=y) / P(A=a, Y=y)
            weights[idx] = expected_p_ay / p_ay
    
    return weights

def disparate_impact_remover(X, sensitive_attr, repair_level=1.0):
    """
    Transforme les caract√©ristiques pour r√©duire l'impact disparate.
    """
    X_transformed = X.copy()
    
    # Pour chaque caract√©ristique
    for col in range(X.shape[1]):
        # V√©rifier si la caract√©ristique est num√©rique (pas un one-hot encoding)
        if np.array_equal(X[:, col], X[:, col].astype(int)) and len(np.unique(X[:, col])) <= 2:
            # Probablement une colonne binaire encod√©e, on la laisse telle quelle
            continue
            
        feature = X[:, col]
        
        # Pour chaque groupe
        groups = np.unique(sensitive_attr)
        transformed_feature = np.zeros_like(feature)
        
        for group in groups:
            group_mask = (sensitive_attr == group)
            group_feature = feature[group_mask]
            
            # Calculer les rangs dans le groupe
            if len(group_feature) > 0:
                ranks = np.argsort(np.argsort(group_feature))
                ranks = ranks / max(1, len(ranks) - 1)  # Normaliser entre 0 et 1
                
                # Interpoler entre la distribution originale et uniforme
                transformed_feature[group_mask] = (1 - repair_level) * group_feature + repair_level * ranks
    
        X_transformed[:, col] = transformed_feature
    
    return X_transformed

def adversarial_debiasing(X_train, y_train, sensitive_attr_train, X_test, base_model):
    """
    Simule un d√©biaisage adversarial (version simplifi√©e).
    En pratique, cela n√©cessiterait une impl√©mentation de r√©seaux adversaires.
    """
    # Stratifier l'√©chantillonnage par attribut sensible
    models = {}
    predictions = np.zeros(len(X_test))
    
    for group in np.unique(sensitive_attr_train):
        mask = (sensitive_attr_train == group)
        if np.sum(mask) > 0:
            group_model = clone_model(base_model)
            group_model.fit(X_train[mask], y_train[mask])
            models[group] = group_model
    
    # Pond√©ration des pr√©dictions
    for group, model in models.items():
        group_preds = model.predict(X_test)
        predictions += group_preds / len(models)
    
    return (predictions > 0.5).astype(int)

def clone_model(model):
    """Cr√©e une copie du mod√®le avec les m√™mes hyperparam√®tres."""
    if isinstance(model, LogisticRegression):
        return LogisticRegression(C=model.C, penalty=model.penalty, solver=model.solver, random_state=42)
    elif isinstance(model, RandomForestClassifier):
        return RandomForestClassifier(n_estimators=model.n_estimators, max_depth=model.max_depth, random_state=42)
    elif isinstance(model, GradientBoostingClassifier):
        return GradientBoostingClassifier(n_estimators=model.n_estimators, learning_rate=model.learning_rate, random_state=42)
    elif isinstance(model, SVC):
        return SVC(C=model.C, kernel=model.kernel, probability=True, random_state=42)
    elif isinstance(model, MLPClassifier):
        return MLPClassifier(hidden_layer_sizes=model.hidden_layer_sizes, max_iter=model.max_iter, random_state=42)
    else:
        return model

def threshold_adjustment(y_scores, sensitive_attr, y_true=None, criterion='demographic_parity'):
    """
    Ajuste les seuils de classification par groupe pour r√©duire les disparit√©s.
    """
    groups = np.unique(sensitive_attr)
    thresholds = {}
    predictions = np.zeros_like(y_scores, dtype=int)
    
    if criterion == 'demographic_parity':
        # Trouver des seuils qui √©galisent les taux de pr√©dictions positives
        target_rate = np.mean(y_scores > 0.5)
        
        for group in groups:
            group_mask = (sensitive_attr == group)
            group_scores = y_scores[group_mask]
            
            # Trouver un seuil qui donne le taux cible
            if len(group_scores) > 0:
                sorted_scores = np.sort(group_scores)
                idx = int((1 - target_rate) * len(sorted_scores))
                idx = min(max(0, idx), len(sorted_scores) - 1)
                thresholds[group] = sorted_scores[idx]
            else:
                thresholds[group] = 0.5
                
            # Appliquer le seuil
            predictions[group_mask] = (group_scores >= thresholds[group]).astype(int)
            
    elif criterion == 'equalized_odds' and y_true is not None:
        # Trouver des seuils qui √©galisent TPR et FPR
        for group in groups:
            group_mask = (sensitive_attr == group)
            group_scores = y_scores[group_mask]
            group_true = y_true[group_mask]
            
            if len(group_scores) > 0:
                pos_scores = group_scores[group_true == 1]
                neg_scores = group_scores[group_true == 0]
                
                # Calculer TPR et FPR pour diff√©rents seuils
                thresholds_list = np.linspace(0, 1, 100)
                best_threshold = 0.5
                min_diff = float('inf')
                
                for t in thresholds_list:
                    if len(pos_scores) > 0:
                        tpr = np.mean(pos_scores >= t)
                    else:
                        tpr = 0
                        
                    if len(neg_scores) > 0:
                        fpr = np.mean(neg_scores >= t)
                    else:
                        fpr = 0
                        
                    # Diff√©rence entre TPR et FPR global
                    diff = abs(tpr - np.mean(y_scores[y_true == 1] >= 0.5)) + abs(fpr - np.mean(y_scores[y_true == 0] >= 0.5))
                    
                    if diff < min_diff:
                        min_diff = diff
                        best_threshold = t
                        
                thresholds[group] = best_threshold
            else:
                thresholds[group] = 0.5
                
            # Appliquer le seuil
            predictions[group_mask] = (group_scores >= thresholds[group]).astype(int)
    else:
        # Par d√©faut: seuil 0.5
        predictions = (y_scores >= 0.5).astype(int)
    
    return predictions, thresholds

# Fonction pour d√©tecter les colonnes cat√©gorielles
def detect_categorical_columns(df):
    categorical_columns = []
    for column in df.columns:
        # D√©tecter les colonnes cat√©gorielles de mani√®re plus robuste
        if (df[column].dtype == 'object' or 
            df[column].dtype.name == 'category' or 
            (df[column].dtype in ['int64', 'float64'] and df[column].nunique() < 10) or
            df[column].apply(lambda x: isinstance(x, str)).any()):
            categorical_columns.append(column)
    return categorical_columns

# Fonction pour analyser le dataframe et comprendre sa structure
def analyze_dataframe(df):
    """Analyse d√©taill√©e du dataframe pour d√©bugger"""
    analysis = {}
    
    # Informations g√©n√©rales
    analysis["shape"] = df.shape
    analysis["columns"] = df.columns.tolist()
    analysis["dtypes"] = df.dtypes.apply(lambda x: str(x)).to_dict()
    
    # Nombre de valeurs uniques par colonne
    analysis["nunique"] = {col: df[col].nunique() for col in df.columns}
    
    # √âchantillon de valeurs pour chaque colonne
    analysis["sample_values"] = {col: df[col].sample(min(5, len(df))).tolist() for col in df.columns}
    
    # Valeurs manquantes
    analysis["missing_values"] = df.isnull().sum().to_dict()
    
    # D√©tection automatique des colonnes cat√©gorielles
    analysis["categorical_columns"] = detect_categorical_columns(df)
    
    # Colonnes qui contiennent des cha√Ænes de caract√®res
    analysis["string_columns"] = [col for col in df.columns if df[col].apply(lambda x: isinstance(x, str)).any()]
    
    return analysis

# Fonction pour pr√©traiter les donn√©es de mani√®re robuste
def preprocess_data_robust(df, feature_cols, target_col, sensitive_col):
    """
    Pr√©traite les donn√©es en g√©rant correctement tous les types de variables
    et en effectuant les encodages n√©cessaires.
    """
    # Analyse des types de colonnes
    categorical_cols = []
    numerical_cols = []
    
    # Pour chaque caract√©ristique (feature)
    for col in feature_cols:
        # Si c'est une colonne de type objet, cat√©gorielle, ou avec peu de valeurs uniques, 
        # ou si elle contient des cha√Ænes de caract√®res
        if (df[col].dtype == 'object' or 
            df[col].dtype.name == 'category' or 
            df[col].apply(lambda x: isinstance(x, str)).any() or
            (df[col].dtype in ['int64', 'float64'] and df[col].nunique() < 10)):
            categorical_cols.append(col)
        else:
            numerical_cols.append(col)
    
    # Cr√©ation des encodeurs pour les colonnes cat√©gorielles
    encoders = {}
    
    # Pr√©traitement des caract√©ristiques
    if categorical_cols and numerical_cols:
        # Si nous avons √† la fois des colonnes cat√©gorielles et num√©riques
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', StandardScaler(), numerical_cols),
                ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), categorical_cols)
            ]
        )
    elif categorical_cols:
        # Si nous n'avons que des colonnes cat√©gorielles
        preprocessor = ColumnTransformer(
            transformers=[
                ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), categorical_cols)
            ]
        )
    elif numerical_cols:
        # Si nous n'avons que des colonnes num√©riques
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', StandardScaler(), numerical_cols)
            ]
        )
    else:
        # Si nous n'avons aucune colonne (ne devrait pas arriver normalement)
        raise ValueError("Aucune colonne valide trouv√©e parmi les caract√©ristiques")
    
    # Transformation des caract√©ristiques
    X = df[feature_cols].copy()
    X_preprocessed = preprocessor.fit_transform(X)
    
    # Traitement de la variable cible
    # Si la cible est cat√©gorielle, l'encoder
    if (df[target_col].dtype == 'object' or 
        df[target_col].dtype.name == 'category' or 
        df[target_col].apply(lambda x: isinstance(x, str)).any()):
        y_encoder = LabelEncoder()
        y = y_encoder.fit_transform(df[target_col])
        encoders['target'] = y_encoder
    else:
        y = df[target_col].values
    
    # Traitement de l'attribut sensible
    # Si l'attribut sensible est cat√©goriel, l'encoder
    if (df[sensitive_col].dtype == 'object' or 
        df[sensitive_col].dtype.name == 'category' or 
        df[sensitive_col].apply(lambda x: isinstance(x, str)).any()):
        sensitive_encoder = LabelEncoder()
        sensitive_attr = sensitive_encoder.fit_transform(df[sensitive_col])
        encoders['sensitive'] = sensitive_encoder
    else:
        sensitive_attr = df[sensitive_col].values
    
    return X_preprocessed, y, sensitive_attr, encoders, preprocessor

# Interface utilisateur Streamlit
def main():
    st.title("üìä Analyse d'√âquit√© Algorithmique")
    st.markdown("*Un outil pour d√©tecter et att√©nuer les biais dans les mod√®les pr√©dictifs*")
    
    # Section d'introduction
    st.header("Introduction √† l'√âquit√© Algorithmique")
    col1, col2 = st.columns(2)
    
    with col1:
        st.info("""
        **D√©finition**
        
        Un mod√®le est √©quitable s'il ne favorise ou ne d√©savantage aucun groupe particulier d√©fini par des attributs sensibles.
        """)
    
    with col2:
        st.warning("""
        **Probl√©matique**
        
        Les mod√®les peuvent amplifier les biais pr√©sents dans les donn√©es d'entra√Ænement ou introduire de nouveaux biais.
        """)
    
    # Barre lat√©rale pour les options
    with st.sidebar:
        st.header("Configuration")
        
        # T√©l√©chargement de fichier
        uploaded_file = st.file_uploader("Charger un dataset (CSV)", type=["csv"])
        
        # Options de mod√®le
        model_type = st.selectbox(
            "Choisir un mod√®le",
            ["R√©gression Logistique", "Random Forest", "Gradient Boosting", "SVM", "R√©seau de Neurones"]
        )
        
        # Options d'√©quit√©
        st.subheader("Techniques d'√©quit√©")
        fairness_techniques = st.multiselect(
            "S√©lectionner les techniques √† appliquer",
            ["Repond√©ration", "Disparate Impact Remover", "Ajustement de seuil", "D√©biaisage adversarial"],
            default=["Repond√©ration"]
        )
        
        # Option de d√©bogage
        debug_mode = st.checkbox("Mode d√©bogage", value=True)
        
        # Param√®tres avanc√©s (facultatifs)
        with st.expander("Param√®tres avanc√©s"):
            test_size = st.slider("Proportion de test", 0.1, 0.5, 0.3, 0.05)
            random_state = st.slider("Graine al√©atoire", 0, 100, 42)
            
            if "Disparate Impact Remover" in fairness_techniques:
                repair_level = st.slider("Niveau de r√©paration", 0.0, 1.0, 0.8, 0.1)
            
            if "Ajustement de seuil" in fairness_techniques:
                threshold_criterion = st.selectbox(
                    "Crit√®re d'ajustement",
                    ["demographic_parity", "equalized_odds"]
                )
    
    # Partie principale de l'application
    if uploaded_file is not None:
        try:
            # Chargement des donn√©es
            df = pd.read_csv(uploaded_file)
            
            # Afficher l'aper√ßu du dataset
            st.subheader("Aper√ßu du dataset")
            st.dataframe(df.head())
            
            # Configuration de la pr√©paration des donn√©es
            st.subheader("Pr√©paration des donn√©es")
            
            # S√©lection des colonnes
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("S√©lectionner les colonnes du mod√®le")
                feature_cols = st.multiselect(
                    "Caract√©ristiques",
                    df.columns.tolist(),
                    default=[col for col in df.columns if col not in [''] and df[col].nunique() > 1][:min(5, len(df.columns))]
                )
                
                target_options = [col for col in df.columns if col not in feature_cols]
                if target_options:
                    target_col = st.selectbox(
                        "Variable cible (binaire)",
                        target_options
                    )
                else:
                    target_col = st.selectbox(
                        "Variable cible (binaire)",
                        df.columns.tolist()
                    )
                    if target_col in feature_cols:
                        feature_cols.remove(target_col)
                        st.warning(f"'{target_col}' a √©t√© retir√© des caract√©ristiques car c'est la variable cible.")
            
            with col2:
                st.write("S√©lectionner l'attribut sensible")
                sensitive_options = [col for col in df.columns if col not in [target_col] + feature_cols]
                if sensitive_options:
                    sensitive_col = st.selectbox(
                        "Attribut sensible (groupe prot√©g√©)",
                        sensitive_options
                    )
                else:
                    sensitive_col = st.selectbox(
                        "Attribut sensible (groupe prot√©g√©)",
                        df.columns.tolist()
                    )
                    if sensitive_col in feature_cols:
                        feature_cols.remove(sensitive_col)
                        st.warning(f"'{sensitive_col}' a √©t√© retir√© des caract√©ristiques car c'est l'attribut sensible.")
                
                # V√©rification que les colonnes s√©lectionn√©es sont valides
                if not feature_cols:
                    st.error("Veuillez s√©lectionner au moins une caract√©ristique.")
                    return
                
                if target_col in feature_cols:
                    feature_cols.remove(target_col)
                    st.warning(f"'{target_col}' a √©t√© retir√© des caract√©ristiques car c'est la variable cible.")
                    
                if sensitive_col in feature_cols:
                    feature_cols.remove(sensitive_col)
                    st.warning(f"'{sensitive_col}' a √©t√© retir√© des caract√©ristiques car c'est l'attribut sensible.")
            
            # Pr√©paration des donn√©es
            if st.button("Analyser et appliquer les techniques d'√©quit√©"):
                with st.spinner("Traitement en cours..."):
                    # Mode d√©bogage - Analyse du dataframe
                    if debug_mode:
                        with st.expander("Informations de d√©bogage"):
                            st.subheader("Analyse du dataframe")
                            analysis = analyze_dataframe(df)
                            
                            st.write(f"Dimensions du dataframe: {analysis['shape']}")
                            st.write(f"Colonnes: {analysis['columns']}")
                            
                            st.subheader("Types de donn√©es")
                            st.write(analysis['dtypes'])
                            
                            st.subheader("Colonnes cat√©gorielles d√©tect√©es")
                            st.write(analysis['categorical_columns'])
                            
                            st.subheader("Colonnes contenant des cha√Ænes de caract√®res")
                            st.write(analysis['string_columns'])
                            
                            st.subheader("Valeurs uniques par colonne")
                            st.write(analysis['nunique'])
                            
                            st.subheader("√âchantillon de valeurs par colonne")
                            st.json(analysis['sample_values'])
                    
                    # Pr√©traitement robuste des donn√©es
                    try:
                        X_preprocessed, y, sensitive_attr, encoders, preprocessor = preprocess_data_robust(
                            df, feature_cols, target_col, sensitive_col
                        )
                        
                        if debug_mode:
                            with st.expander("Informations sur les donn√©es pr√©trait√©es"):
                                st.write(f"Forme des donn√©es pr√©trait√©es: {X_preprocessed.shape}")
                                st.write(f"Variable cible: {np.unique(y)}, forme: {y.shape}")
                                st.write(f"Attribut sensible: {np.unique(sensitive_attr)}, forme: {sensitive_attr.shape}")
                                
                                # Afficher les encodeurs si disponibles
                                if 'target' in encoders:
                                    st.write(f"Classes de la cible: {encoders['target'].classes_}")
                                if 'sensitive' in encoders:
                                    st.write(f"Classes de l'attribut sensible: {encoders['sensitive'].classes_}")
                        
                        # V√©rifier si la variable cible est binaire
                        unique_y = np.unique(y)
                        if len(unique_y) != 2:
                            st.error(f"La variable cible doit √™tre binaire. La colonne '{target_col}' contient {len(unique_y)} valeurs uniques.")
                            return
                            
                    except Exception as e:
                        st.error(f"Erreur lors du pr√©traitement des donn√©es: {str(e)}")
                        if debug_mode:
                            st.write("Trace compl√®te de l'erreur:")
                            st.code(traceback.format_exc())
                        return
                    
                    # Division des donn√©es
                    X_train, X_test, y_train, y_test, sens_train, sens_test = train_test_split(
                        X_preprocessed, y, sensitive_attr, test_size=test_size, random_state=random_state, stratify=y
                    )
                    
                    # Cr√©ation du mod√®le de base
                    if model_type == "R√©gression Logistique":
                        base_model = LogisticRegression(random_state=random_state, max_iter=1000)
                    elif model_type == "Random Forest":
                        base_model = RandomForestClassifier(n_estimators=100, random_state=random_state)
                    elif model_type == "Gradient Boosting":
                        base_model = GradientBoostingClassifier(random_state=random_state)
                    elif model_type == "SVM":
                        base_model = SVC(probability=True, random_state=random_state)
                    elif model_type == "R√©seau de Neurones":
                        base_model = MLPClassifier(hidden_layer_sizes=(50, 25), max_iter=1000, random_state=random_state)
                    
                    # Entra√Ænement et √©valuation du mod√®le de base
                    try:
                        base_model.fit(X_train, y_train)
                        
                        if hasattr(base_model, 'predict_proba'):
                            base_probas = base_model.predict_proba(X_test)[:, 1]
                        else:
                            # Pour les mod√®les comme SVM qui n'ont pas toujours predict_proba
                            try:
                                base_probas = base_model.decision_function(X_test)
                                # Normalisation des scores entre 0 et 1 pour √™tre utilisables comme des probabilit√©s
                                base_probas = (base_probas - base_probas.min()) / (base_probas.max() - base_probas.min())
                            except:
                                base_probas = None
                                if debug_mode:
                                    st.warning("Ce mod√®le ne fournit pas de probabilit√©s. Certaines m√©triques et techniques d'√©quit√© pourraient ne pas √™tre disponibles.")
                        
                        base_preds = base_model.predict(X_test)
                        
                        # M√©triques du mod√®le de base
                        base_metrics = {
                            "Pr√©cision": accuracy_score(y_test, base_preds),
                            "Rappel": recall_score(y_test, base_preds, zero_division=0),
                            "F1-score": f1_score(y_test, base_preds, zero_division=0),
                            "AUC": roc_auc_score(y_test, base_probas) if base_probas is not None else None
                        }
                        
                        # M√©triques d'√©quit√© du mod√®le de base
                        base_dp, base_dp_disparity = demographic_parity(base_preds, sens_test, encoders.get('sensitive'))
                        base_eo, base_tpr_disparity, base_fpr_disparity = equalized_odds(y_test, base_preds, sens_test, encoders.get('sensitive'))
                        base_eop, base_eop_disparity = equal_opportunity(y_test, base_preds, sens_test, encoders.get('sensitive'))
                        base_pp, base_pp_disparity = predictive_parity(y_test, base_preds, sens_test, encoders.get('sensitive'))
                        
                        base_fairness_metrics = {
                            "Disparit√© de parit√© d√©mographique": base_dp_disparity,
                            "Disparit√© TPR": base_tpr_disparity,
                            "Disparit√© FPR": base_fpr_disparity,
                            "Disparit√© d'√©galit√© des chances": base_eop_disparity,
                            "Disparit√© de parit√© pr√©dictive": base_pp_disparity
                        }
                        
                    except Exception as e:
                        st.error(f"Erreur lors de l'entra√Ænement ou de l'√©valuation du mod√®le: {str(e)}")
                        if debug_mode:
                            st.write("Trace compl√®te de l'erreur:")
                            st.code(traceback.format_exc())
                        return
                    
                    # Appliquer les techniques d'√©quit√© s√©lectionn√©es
                    fairness_results = {}
                    
                    for technique in fairness_techniques:
                        try:
                            if technique == "Repond√©ration":
                                weights = reweighing(X_train, y_train, sens_train)
                                fair_model = clone_model(base_model)
                                fair_model.fit(X_train, y_train, sample_weight=weights)
                                
                                if hasattr(fair_model, 'predict_proba'):
                                    fair_probas = fair_model.predict_proba(X_test)[:, 1]
                                else:
                                    try:
                                        fair_probas = fair_model.decision_function(X_test)
                                        fair_probas = (fair_probas - fair_probas.min()) / (fair_probas.max() - fair_probas.min())
                                    except:
                                        fair_probas = None
                                
                                fair_preds = fair_model.predict(X_test)
                                
                            elif technique == "Disparate Impact Remover":
                                repair_level_val = repair_level if "repair_level" in locals() else 0.8
                                X_train_repaired = disparate_impact_remover(X_train, sens_train, repair_level_val)
                                X_test_repaired = disparate_impact_remover(X_test, sens_test, repair_level_val)
                                
                                fair_model = clone_model(base_model)
                                fair_model.fit(X_train_repaired, y_train)
                                
                                if hasattr(fair_model, 'predict_proba'):
                                    fair_probas = fair_model.predict_proba(X_test_repaired)[:, 1]
                                else:
                                    try:
                                        fair_probas = fair_model.decision_function(X_test_repaired)
                                        fair_probas = (fair_probas - fair_probas.min()) / (fair_probas.max() - fair_probas.min())
                                    except:
                                        fair_probas = None
                                
                                fair_preds = fair_model.predict(X_test_repaired)
                                
                            elif technique == "Ajustement de seuil":
                                if base_probas is not None:
                                    criterion = threshold_criterion if "threshold_criterion" in locals() else "demographic_parity"
                                    fair_preds, thresholds = threshold_adjustment(base_probas, sens_test, y_test, criterion)
                                    fair_probas = base_probas
                                else:
                                    st.warning(f"L'ajustement de seuil n√©cessite des probabilit√©s, ce qui n'est pas disponible pour {model_type}. Technique ignor√©e.")
                                    continue
                                    
                            elif technique == "D√©biaisage adversarial":
                                fair_preds = adversarial_debiasing(X_train, y_train, sens_train, X_test, base_model)
                                fair_probas = None
                            
                            # M√©triques du mod√®le √©quitable
                            fair_metrics = {
                                "Pr√©cision": accuracy_score(y_test, fair_preds),
                                "Rappel": recall_score(y_test, fair_preds, zero_division=0),
                                "F1-score": f1_score(y_test, fair_preds, zero_division=0),
                                "AUC": roc_auc_score(y_test, fair_probas) if fair_probas is not None else None
                            }
                            
                            # M√©triques d'√©quit√© du mod√®le √©quitable
                            fair_dp, fair_dp_disparity = demographic_parity(fair_preds, sens_test, encoders.get('sensitive'))
                            fair_eo, fair_tpr_disparity, fair_fpr_disparity = equalized_odds(y_test, fair_preds, sens_test, encoders.get('sensitive'))
                            fair_eop, fair_eop_disparity = equal_opportunity(y_test, fair_preds, sens_test, encoders.get('sensitive'))
                            fair_pp, fair_pp_disparity = predictive_parity(y_test, fair_preds, sens_test, encoders.get('sensitive'))
                            
                            fair_fairness_metrics = {
                                "Disparit√© de parit√© d√©mographique": fair_dp_disparity,
                                "Disparit√© TPR": fair_tpr_disparity,
                                "Disparit√© FPR": fair_fpr_disparity,
                                "Disparit√© d'√©galit√© des chances": fair_eop_disparity,
                                "Disparit√© de parit√© pr√©dictive": fair_pp_disparity
                            }
                            
                            # Stocker les r√©sultats
                            fairness_results[technique] = {
                                "M√©triques de performance": fair_metrics,
                                "M√©triques d'√©quit√©": fair_fairness_metrics,
                                "Parit√© d√©mographique": fair_dp,
                                "√âgalit√© des chances": {"TPR": {k: v["TPR"] for k, v in fair_eo.items()}, 
                                                      "FPR": {k: v["FPR"] for k, v in fair_eo.items()}},
                                "√âgalit√© des opportunit√©s": fair_eop,
                                "Parit√© pr√©dictive": fair_pp
                            }
                        except Exception as e:
                            st.warning(f"Erreur lors de l'application de la technique '{technique}': {str(e)}")
                            if debug_mode:
                                st.write("Trace compl√®te de l'erreur:")
                                st.code(traceback.format_exc())
                    
                    # Afficher les r√©sultats
                    st.header("R√©sultats")
                    
                    # Mod√®le de base
                    st.subheader("Mod√®le de base")
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write("M√©triques de performance")
                        performance_df = pd.DataFrame([base_metrics])
                        st.dataframe(performance_df)
                        
                    with col2:
                        st.write("M√©triques d'√©quit√©")
                        fairness_df = pd.DataFrame([base_fairness_metrics])
                        st.dataframe(fairness_df)
                    
                    # Visualisations pour le mod√®le de base
                    st.subheader("Visualisations du mod√®le de base")
                    
                    try:
                        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
                        
                        # Parit√© D√©mographique
                        ax = axes[0, 0]
                        groups = list(base_dp.keys())
                        values = list(base_dp.values())
                        ax.bar(groups, values, color='salmon')
                        ax.set_title('Parit√© D√©mographique')
                        ax.set_ylabel('Taux de pr√©dictions positives')
                        ax.set_ylim(0, 1)
                        
                        # √âgalit√© des Taux d'Erreurs
                        ax = axes[0, 1]
                        groups = list(base_eo.keys())
                        tpr_values = [v["TPR"] for v in base_eo.values()]
                        fpr_values = [v["FPR"] for v in base_eo.values()]
                        
                        x = np.arange(len(groups))
                        width = 0.35
                        
                        ax.bar(x - width/2, tpr_values, width, label='TPR', color='mediumorchid')
                        ax.bar(x + width/2, fpr_values, width, label='FPR', color='plum')
                        ax.set_title('√âgalit√© des Taux d\'Erreurs')
                        ax.set_xticks(x)
                        ax.set_xticklabels(groups)
                        ax.set_ylabel('Taux')
                        ax.set_ylim(0, 1)
                        ax.legend()
                        
                        # √âgalit√© des Chances
                        ax = axes[1, 0]
                        groups = list(base_eop.keys())
                        values = list(base_eop.values())
                        ax.bar(groups, values, color='cornflowerblue')
                        ax.set_title('√âgalit√© des Chances')
                        ax.set_ylabel('Taux de vrais positifs')
                        ax.set_ylim(0, 1)
                        
                        # √âquilibre des Taux de Pr√©cision
                        ax = axes[1, 1]
                        groups = list(base_pp.keys())
                        values = list(base_pp.values())
                        ax.bar(groups, values, color='mediumseagreen')
                        ax.set_title('√âquilibre des Taux de Pr√©cision')
                        ax.set_ylabel('Pr√©cision parmi les pr√©dictions positives')
                        ax.set_ylim(0, 1)
                        
                        plt.tight_layout()
                        st.pyplot(fig)
                    except Exception as e:
                        st.error(f"Erreur lors de la g√©n√©ration des visualisations: {str(e)}")
                        if debug_mode:
                            st.write("Trace compl√®te de l'erreur:")
                            st.code(traceback.format_exc())
                    
                    # Matrice de confusion par groupe
                    st.subheader("Matrices de confusion par groupe")
                    
                    try:
                        unique_groups = np.unique(sens_test)
                        n_groups = len(unique_groups)
                        
                        fig, axes = plt.subplots(1, n_groups, figsize=(5*n_groups, 4))
                        if n_groups == 1:
                            axes = [axes]
                            
                        for i, group in enumerate(unique_groups):
                            group_mask = (sens_test == group)
                            cm = confusion_matrix(y_test[group_mask], base_preds[group_mask])
                            
                            if 'sensitive' in encoders:
                                group_name = encoders['sensitive'].inverse_transform([group])[0]
                            else:
                                group_name = f"Groupe {group}"
                            
                            sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=axes[i])
                            axes[i].set_title(f'{group_name}')
                            axes[i].set_xlabel('Pr√©diction')
                            axes[i].set_ylabel('Valeur r√©elle')
                        
                        plt.tight_layout()
                        st.pyplot(fig)
                    except Exception as e:
                        st.error(f"Erreur lors de la g√©n√©ration des matrices de confusion: {str(e)}")
                        if debug_mode:
                            st.write("Trace compl√®te de l'erreur:")
                            st.code(traceback.format_exc())
                    
                    # R√©sultats des techniques d'√©quit√©
                    if fairness_results:
                        st.header("Comparaison des techniques d'√©quit√©")
                        
                        # Tableau comparatif des performances
                        st.subheader("Comparaison des m√©triques de performance")
                        
                        performance_comparison = {
                            "Mod√®le de base": base_metrics
                        }
                        
                        for technique, results in fairness_results.items():
                            performance_comparison[technique] = results["M√©triques de performance"]
                            
                        performance_df = pd.DataFrame(performance_comparison).T
                        st.dataframe(performance_df)
                        
                        # Tableau comparatif des m√©triques d'√©quit√©
                        st.subheader("Comparaison des m√©triques d'√©quit√©")
                        
                        fairness_comparison = {
                            "Mod√®le de base": base_fairness_metrics
                        }
                        
                        for technique, results in fairness_results.items():
                            fairness_comparison[technique] = results["M√©triques d'√©quit√©"]
                            
                        fairness_df = pd.DataFrame(fairness_comparison).T
                        st.dataframe(fairness_df)
                        
                        # Visualisations comparatives
                        st.subheader("Comparaison visuelle des m√©triques d'√©quit√©")
                        
                        try:
                            # Pr√©parer les donn√©es pour les graphiques
                            techniques = ["Mod√®le de base"] + list(fairness_results.keys())
                            
                            dp_disparities = [base_dp_disparity] + [results["M√©triques d'√©quit√©"]["Disparit√© de parit√© d√©mographique"] 
                                                                 for results in fairness_results.values()]
                            
                            eop_disparities = [base_eop_disparity] + [results["M√©triques d'√©quit√©"]["Disparit√© d'√©galit√© des chances"] 
                                                                    for results in fairness_results.values()]
                            
                            pp_disparities = [base_pp_disparity] + [results["M√©triques d'√©quit√©"]["Disparit√© de parit√© pr√©dictive"] 
                                                                  for results in fairness_results.values()]
                            
                            # Graphiques comparatifs
                            fig, axes = plt.subplots(1, 3, figsize=(18, 5))
                            
                            # Disparit√© de parit√© d√©mographique
                            axes[0].bar(techniques, dp_disparities, color='salmon')
                            axes[0].set_title('Disparit√© de parit√© d√©mographique')
                            axes[0].set_ylabel('Disparit√©')
                            plt.setp(axes[0].get_xticklabels(), rotation=45, ha='right')
                            
                            # Disparit√© d'√©galit√© des chances
                            axes[1].bar(techniques, eop_disparities, color='cornflowerblue')
                            axes[1].set_title('Disparit√© d\'√©galit√© des chances')
                            axes[1].set_ylabel('Disparit√©')
                            plt.setp(axes[1].get_xticklabels(), rotation=45, ha='right')
                            
                            # Disparit√© de parit√© pr√©dictive
                            axes[2].bar(techniques, pp_disparities, color='mediumseagreen')
                            axes[2].set_title('Disparit√© de parit√© pr√©dictive')
                            axes[2].set_ylabel('Disparit√©')
                            plt.setp(axes[2].get_xticklabels(), rotation=45, ha='right')
                            
                            plt.tight_layout()
                            st.pyplot(fig)
                        except Exception as e:
                            st.error(f"Erreur lors de la g√©n√©ration des visualisations comparatives: {str(e)}")
                            if debug_mode:
                                st.write("Trace compl√®te de l'erreur:")
                                st.code(traceback.format_exc())
                        
                        # √âvaluation d√©taill√©e des techniques
                        st.header("Analyse d√©taill√©e des techniques d'√©quit√©")
                        
                        for technique, results in fairness_results.items():
                            with st.expander(f"D√©tails pour {technique}"):
                                st.subheader(f"M√©triques de parit√© pour {technique}")
                                
                                col1, col2 = st.columns(2)
                                
                                with col1:
                                    # Parit√© D√©mographique
                                    st.write("**Parit√© D√©mographique**")
                                    dp_data = results["Parit√© d√©mographique"]
                                    dp_df = pd.DataFrame(dp_data.items(), columns=["Groupe", "Taux de pr√©dictions positives"])
                                    st.dataframe(dp_df)
                                    
                                    # √âgalit√© des Opportunit√©s
                                    st.write("**√âgalit√© des Opportunit√©s**")
                                    eop_data = results["√âgalit√© des opportunit√©s"]
                                    eop_df = pd.DataFrame(eop_data.items(), columns=["Groupe", "Taux de vrais positifs"])
                                    st.dataframe(eop_df)
                                
                                with col2:
                                    # √âgalit√© des Chances (TPR)
                                    st.write("**√âgalit√© des Chances (TPR)**")
                                    tpr_data = results["√âgalit√© des chances"]["TPR"]
                                    tpr_df = pd.DataFrame(tpr_data.items(), columns=["Groupe", "TPR"])
                                    st.dataframe(tpr_df)
                                    
                                    # Parit√© Pr√©dictive
                                    st.write("**Parit√© Pr√©dictive**")
                                    pp_data = results["Parit√© pr√©dictive"]
                                    pp_df = pd.DataFrame(pp_data.items(), columns=["Groupe", "Pr√©cision parmi pr√©dictions positives"])
                                    st.dataframe(pp_df)
                                
                                # Matrice de confusion par groupe pour cette technique
                                st.write("**Matrices de confusion par groupe**")
                                
                                try:
                                    if technique == "Ajustement de seuil":
                                        fair_preds = fairness_results[technique].get("predictions", 
                                                                                  threshold_adjustment(base_probas, sens_test, y_test)[0])
                                    elif technique == "D√©biaisage adversarial":
                                        fair_preds = adversarial_debiasing(X_train, y_train, sens_train, X_test, base_model)
                                    else:
                                        fair_model = clone_model(base_model)
                                        if technique == "Repond√©ration":
                                            weights = reweighing(X_train, y_train, sens_train)
                                            fair_model.fit(X_train, y_train, sample_weight=weights)
                                            fair_preds = fair_model.predict(X_test)
                                        elif technique == "Disparate Impact Remover":
                                            repair_level_val = repair_level if "repair_level" in locals() else 0.8
                                            X_train_repaired = disparate_impact_remover(X_train, sens_train, repair_level_val)
                                            X_test_repaired = disparate_impact_remover(X_test, sens_test, repair_level_val)
                                            fair_model.fit(X_train_repaired, y_train)
                                            fair_preds = fair_model.predict(X_test_repaired)
                                    
                                    fig, axes = plt.subplots(1, n_groups, figsize=(5*n_groups, 4))
                                    if n_groups == 1:
                                        axes = [axes]
                                        
                                    for i, group in enumerate(unique_groups):
                                        group_mask = (sens_test == group)
                                        cm = confusion_matrix(y_test[group_mask], fair_preds[group_mask])
                                        
                                        if 'sensitive' in encoders:
                                            group_name = encoders['sensitive'].inverse_transform([group])[0]
                                        else:
                                            group_name = f"Groupe {group}"
                                        
                                        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=axes[i])
                                        axes[i].set_title(f'{group_name}')
                                        axes[i].set_xlabel('Pr√©diction')
                                        axes[i].set_ylabel('Valeur r√©elle')
                                    
                                    plt.tight_layout()
                                    st.pyplot(fig)
                                except Exception as e:
                                    st.error(f"Erreur lors de la g√©n√©ration des matrices de confusion pour {technique}: {str(e)}")
                                    if debug_mode:
                                        st.write("Trace compl√®te de l'erreur:")
                                        st.code(traceback.format_exc())
                        
                        # Recommandation finale
                        st.header("Recommandation")
                        
                        try:
                            # Calculer un score composite pour chaque technique (trade-off performance-√©quit√©)
                            # Plus petit = meilleur
                            composite_scores = {}
                            
                            # Base model as reference
                            base_perf = (base_metrics["F1-score"] if base_metrics["F1-score"] is not None else 0)
                            base_fairness = np.mean([v for v in base_fairness_metrics.values() if v is not None and not np.isnan(v)])
                            
                            for technique, results in fairness_results.items():
                                perf_metrics = results["M√©triques de performance"]
                                fair_metrics = results["M√©triques d'√©quit√©"]
                                
                                # Performance relative (F1-score)
                                perf = (perf_metrics["F1-score"] if perf_metrics["F1-score"] is not None else 0)
                                perf_diff = max(0, base_perf - perf)  # P√©nalit√© si performance diminue
                                
                                # √âquit√© relative (moyenne des disparit√©s)
                                fairness = np.mean([v for v in fair_metrics.values() if v is not None and not np.isnan(v)])
                                fairness_improvement = max(0, base_fairness - fairness)  # Bonus si √©quit√© s'am√©liore
                                
                                # Score composite (plus petit = meilleur)
                                composite_scores[technique] = perf_diff - fairness_improvement
                            
                            # Trouver la meilleure technique
                            if composite_scores:
                                best_technique = min(composite_scores.items(), key=lambda x: x[1])[0]
                                
                                st.info(f"**Technique recommand√©e : {best_technique}**")
                                st.write("Cette technique offre le meilleur compromis entre la performance du mod√®le et l'√©quit√© algorithmique pour ce dataset.")
                                
                                # D√©tails sur la technique recommand√©e
                                st.write(f"**D√©tails sur {best_technique}:**")
                                
                                if best_technique == "Repond√©ration":
                                    st.write("Cette technique attribue des poids aux √©chantillons d'entra√Ænement pour garantir une repr√©sentation √©quilibr√©e des groupes prot√©g√©s et non prot√©g√©s.")
                                elif best_technique == "Disparate Impact Remover":
                                    st.write("Cette technique transforme les caract√©ristiques pour r√©duire les corr√©lations avec l'attribut sensible tout en pr√©servant la capacit√© pr√©dictive.")
                                elif best_technique == "Ajustement de seuil":
                                    st.write("Cette technique applique des seuils de classification diff√©rents pour chaque groupe afin d'√©quilibrer les taux de pr√©dictions positives ou les taux d'erreur.")
                                elif best_technique == "D√©biaisage adversarial":
                                    st.write("Cette technique utilise une approche d'apprentissage adversaire pour r√©duire les biais en emp√™chant le mod√®le d'apprendre des corr√©lations avec l'attribut sensible.")
                            else:
                                st.warning("Aucune technique d'√©quit√© n'a √©t√© appliqu√©e ou √©valu√©e.")
                        except Exception as e:
                            st.error(f"Erreur lors de la g√©n√©ration de la recommandation: {str(e)}")
                            if debug_mode:
                                st.write("Trace compl√®te de l'erreur:")
                                st.code(traceback.format_exc())
                    else:
                        st.warning("Aucune technique d'√©quit√© n'a √©t√© s√©lectionn√©e ou appliqu√©e.")
        except Exception as e:
            st.error(f"Une erreur s'est produite lors du traitement des donn√©es : {str(e)}")
            if debug_mode:
                st.write("Trace compl√®te de l'erreur:")
                st.code(traceback.format_exc())

if __name__ == "__main__":
    main()